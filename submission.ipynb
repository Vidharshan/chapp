{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m StandardScaler, OneHotEncoder\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m---> 16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtfa\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mlayers\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "import sklearn as sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.regularizers as reg\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/playground-series-s3e2/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/playground-series-s3e2/test.csv')\n",
    "ss = pd.read_csv('/kaggle/input/playground-series-s3e2/sample_submission.csv')\n",
    "ogdata_df = pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('id', axis=1, inplace=True)\n",
    "ogdata_df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()\n",
    "ogdata_df = ogdata_df[ogdata_df['stroke']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ogdata_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, ogdata_df],axis=0, ignore_index=True)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can observe there is class imbalance\n",
    "sns.countplot(x='stroke', data=train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='heart_disease', data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(train_df.corr(), annot=True, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='age', y='bmi', data=train_df, hue='stroke', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(hue='gender', x='smoking_status', data=train_df)\n",
    "plt.legend(loc=(1.1,0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(x='avg_glucose_level', data=train_df, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='hypertension', y='age', data=train_df, estimator=np.mean, hue='gender')\n",
    "plt.title(\"Avg age of people with hypertension\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_full = train_df.copy()\n",
    "y_full = x_full.pop('stroke').to_numpy()\n",
    "\n",
    "\n",
    "num_cols = [\"age\", \"avg_glucose_level\", \"bmi\"]\n",
    "cat_cols = x_full.columns.difference(num_cols)\n",
    "print(cat_cols)\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "tr = ColumnTransformer([\n",
    "    (\"num\", num_pipe, num_cols),\n",
    "    (\"cat\", OneHotEncoder(drop=\"first\"), cat_cols),\n",
    "])\n",
    "\n",
    "x_full = tr.fit_transform(x_full)\n",
    "x_test = tr.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    d = 0.1\n",
    "    model = tf.keras.models.Sequential([\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(d),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(d),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(d),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tfa.losses.SigmoidFocalCrossEntropy(alpha=0.80, gamma=2.0),\n",
    "        metrics=\"AUC\"\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_auc\", mode='max', patience=3, factor=0.1, min_lr=1e-6, min_delta=0.0001)\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode='max', patience=7, min_delta=0.0001, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "scores = []\n",
    "skf = StratifiedKFold(n_splits=12, shuffle=True)\n",
    "\n",
    "\n",
    "for train_index, val_index in skf.split(x_full, y_full):\n",
    "    x_train, x_val = x_full[train_index], x_full[val_index]\n",
    "    y_train, y_val = y_full[train_index], y_full[val_index]\n",
    "    \n",
    "    model = get_model()\n",
    "    h = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data = (x_val, y_val),\n",
    "        epochs = 100,\n",
    "        batch_size = 64,\n",
    "        callbacks = [plt, es],\n",
    "        class_weight = { 0: 1.0, 1: 10.0, },\n",
    "        verbose=False\n",
    "    ).history\n",
    "    \n",
    "    s = roc_auc_score(y_val, model.predict(x_val))\n",
    "    print(f\"val auc: {s:.4f}\")\n",
    "    scores.append(s)\n",
    "    models.append(model)\n",
    "    \n",
    "print(f'mean scores:  {np.mean(scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "scores = []\n",
    "\n",
    "cb_params = {\n",
    "    'depth': 3,\n",
    "    'learning_rate': 0.01,\n",
    "    'rsm': 0.5,\n",
    "    'subsample': 0.931,\n",
    "    'l2_leaf_reg': 69,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'random_strength': 0.175,\n",
    "    'use_best_model': True,\n",
    "    'task_type': 'CPU',\n",
    "    'bootstrap_type': 'Bernoulli',\n",
    "    'grow_policy': 'SymmetricTree',\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'AUC'\n",
    "}\n",
    "for train_index, val_index in skf.split(x_full, y_full):\n",
    "    cb_train = cb.Pool(data=x_full[train_index], label = y_full[train_index])\n",
    "    cb_valid = cb.Pool(data=x_full[val_index], label = y_full[val_index])\n",
    "    \n",
    "    model = cb.train(params=cb_params,\n",
    "                     dtrain=cb_train,\n",
    "                     num_boost_round=10000,\n",
    "                     evals=cb_valid, \n",
    "                     early_stopping_rounds=500,\n",
    "                     verbose=False)\n",
    "    \n",
    "    s = roc_auc_score(y_full[val_index], model.predict(cb_valid))\n",
    "    print(f\"Best val auc: {s:.4f}\")\n",
    "    scores.append(s)\n",
    "    models.append(model)\n",
    "print(f'mean scores:  {np.mean(scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for train_index, val_index in skf.split(x_full, y_full):\n",
    "    x_train, x_val = x_full[train_index], x_full[val_index]\n",
    "    y_train, y_val = y_full[train_index], y_full[val_index]\n",
    "    \n",
    "    model = LassoCV(\n",
    "    precompute=\"auto\",\n",
    "    fit_intercept=True,\n",
    "    max_iter=1000,\n",
    "    verbose=False,\n",
    "    eps=1e-04,\n",
    "    n_alphas=1000,\n",
    "    n_jobs=8)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    s = roc_auc_score(y_val, model.predict(x_val))\n",
    "    print(f\"Best val auc: {s:.4f}\")\n",
    "    scores.append(s)\n",
    "    models.append(model)\n",
    "print(f'mean scores:  {np.mean(scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_preds = []\n",
    "cb_preds = []\n",
    "lasso_preds = []\n",
    "\n",
    "for model in models[:12]:\n",
    "    nn_preds.append(model.predict(x_test))\n",
    "for model in models[12:24]:\n",
    "    cb_preds.append(model.predict(x_test))\n",
    "for model in models[24:]:\n",
    "    lasso_preds.append(model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_preds = np.array(cb_preds).mean(0)\n",
    "nn_preds = np.array(nn_preds).mean(0)\n",
    "lasso_preds = np.array(lasso_preds).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_preds = nn_preds.reshape((10204,))\n",
    "nn_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss['stroke'] = (cb_preds*0.5 + nn_preds*0.5)*0.5 + lasso_preds*0.5\n",
    "ss.to_csv(\"submission.csv\", index=False)\n",
    "pd.read_csv(\"submission.csv\").head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6491bbd3c7861498ceca5f810ff495ca48eaaad8857aa8ae48a42dff31e5d8e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
